{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "import torch\n",
    "import os\n",
    "import gdal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import geopandas as gpd\n",
    "from IPython.display import Image, clear_output \n",
    "print('PyTorch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imShow(path):\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "\n",
    "    image = cv2.imread(path)\n",
    "    height, width = image.shape[:2]\n",
    "    resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(8, 8)\n",
    "    plt.axis(\"off\")\n",
    "    #plt.rcParams['figure.figsize'] = [10, 5]\n",
    "    plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "outfd = r\"./output/\"\n",
    "\n",
    "def showall(path):\n",
    "    for filename in os.listdir(path):\n",
    "        if filename[-4:] == \".tif\":\n",
    "            img = os.path.join(path,filename)\n",
    "            print(img)\n",
    "            imShow(img)\n",
    "        elif filename[-4:] == \".jpeg\" or filename[-4:] == \".jpg\":\n",
    "            img = os.path.join(path,filename)\n",
    "            print(img)\n",
    "            imShow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # t1f_22, img, t1f_30cm_127, T1F_ORTHO_withGCPs_30cm\n",
    "# source = \"C:\\\\Development\\\\dev_tools\\\\tree-detector-yolo\\\\data\\\\t1f_5.tif\"\n",
    "# cfg = \"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\acacia_dataset\\\\cfg\\\\yolov3-spp-1cls.cfg\"\n",
    "# weights = \"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\acacia_dataset\\\\weights\\\\last_1cls_1300.pt\"\n",
    "# names = \"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\acacia_dataset\\\\acacia.names\"\n",
    "# conf_thres = 0.2\n",
    "# iou_thres = 0.1\n",
    "\n",
    "# !python detect.py \\\n",
    "# --geo \\\n",
    "# --save-geom \\\n",
    "# --save-label \\\n",
    "# --source=\"{source}\" \\\n",
    "# --cfg=\"{cfg}\" \\\n",
    "# --weights=\"{weights}\" \\\n",
    "# --names=\"{names}\" \\\n",
    "# --conf-thres=\"{conf_thres}\" \\\n",
    "# --iou-thres=\"{iou_thres}\" \\\n",
    "# --agnostic-nms \\\n",
    "# --augment\n",
    "\n",
    "# showall(outfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source =\"C:\\\\Development\\\\dev_tools\\\\tree-detector-yolo\\\\data\\\\keresa0000_0002.tif\"\n",
    "# cfg =\"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\satellite_dataset\\\\worldview\\\\cfg\\\\yolov3_spp_1cls_op.cfg\"\n",
    "# weights =\"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\satellite_dataset\\\\worldview\\\\weights\\\\best_oilpalm_wv_500.pt\"\n",
    "# names =\"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\satellite_dataset\\\\worldview\\\\op.names\"\n",
    "# # outDir=\"C:\\\\Map\\\\Deep_learning\\\\digital_globe\\\\011802594010_01\\\\pansharp_rgb_tiles\\\\765\\\\yolo\"\n",
    "# conf_thres = 0.2\n",
    "# iou_thres = 0.1\n",
    "\n",
    "# !python detect.py \\\n",
    "# --geo \\\n",
    "# --save-geom \\\n",
    "# --save-label \\\n",
    "# --source=\"{source}\" \\\n",
    "# --cfg=\"{cfg}\" \\\n",
    "# --weights=\"{weights}\" \\\n",
    "# --names=\"{names}\" \\\n",
    "# --conf-thres=\"{conf_thres}\" \\\n",
    "# --iou-thres=\"{iou_thres}\" \\\n",
    "# --augment\n",
    "\n",
    "# showall(outfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "if platform.node() == 'GPPGIS06':\n",
    "    # # t1f_22, img, t1f_30cm_127, T1F_ORTHO_withGCPs_30cm\n",
    "    source = \"C:\\\\Development\\\\dev_tools\\\\tree-detector-yolo\\\\data\\\\t1f_5.tif\"\n",
    "    cfg = \"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\acacia_dataset\\\\cfg\\\\yolov3-spp-1cls.cfg\"\n",
    "    weights = \"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\acacia_dataset\\\\weights\\\\last_1cls_1300.pt\"\n",
    "    names = \"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\acacia_dataset\\\\acacia.names\"\n",
    "    \n",
    "    source_op = \"C:\\\\Development\\\\dev_tools\\\\tree-detector-yolo\\\\data\\\\digitalglobe_oilpalm_1_4.tif\"\n",
    "    cfg_op =\"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\satellite_dataset\\\\worldview\\\\cfg\\\\yolov3_spp_1cls_op.cfg\"\n",
    "    weights_op =\"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\satellite_dataset\\\\worldview\\\\weights\\\\last_oilpalm_wv_500.pt\"\n",
    "    names_op =\"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\satellite_dataset\\\\worldview\\\\op.names\"\n",
    "    \n",
    "elif platform.node() == 'LWS-PC':\n",
    "    cfg = \"E:\\\\GDrive\\\\acacia_dataset\\\\cfg\\\\yolov3-spp-1cls.cfg\"\n",
    "    weights = \"E:\\\\GDrive\\\\acacia_dataset\\\\weights\\\\last_1cls_1300.pt\"\n",
    "    names = \"E:\\\\GDrive\\\\acacia_dataset\\\\acacia.names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=False, cfg='C:\\\\Users\\\\lerryw\\\\Google Drive\\\\acacia_dataset\\\\cfg\\\\yolov3-spp-1cls.cfg', classes=None, conf_thres=0.2, device='', fourcc='mp4v', half=False, img_size=416, iou_thres=0.2, names='C:\\\\Users\\\\lerryw\\\\Google Drive\\\\acacia_dataset\\\\acacia.names', output='./output', save_txt=False, source='C:\\\\Development\\\\dev_tools\\\\tree-detector-yolo\\\\data\\\\t1f_5.tif', view_img=False, weights='C:\\\\Users\\\\lerryw\\\\Google Drive\\\\acacia_dataset\\\\weights\\\\last_1cls_1300.pt')\n",
      "Using CUDA device0 _CudaDeviceProperties(name='Quadro K620', total_memory=2048MB)\n",
      "\n",
      "Model Summary: 225 layers, 6.25733e+07 parameters, 6.25733e+07 gradients\n",
      "length pred_list :  812\n",
      "New count :  512\n",
      "Done. (11.315s)\n"
     ]
    }
   ],
   "source": [
    "!python detectv2.py --source=\"{source}\" \\\n",
    "--output=./output \\\n",
    "--cfg=\"{cfg}\" \\\n",
    "--weights=\"{weights}\" \\\n",
    "--names=\"{names}\" \\\n",
    "--conf-thres 0.2 \\\n",
    "--iou-thres 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(agnostic_nms=False, augment=False, cfg='C:\\\\Users\\\\lerryw\\\\Google Drive\\\\satellite_dataset\\\\worldview\\\\cfg\\\\yolov3_spp_1cls_op.cfg', classes=None, conf_thres=0.2, device='', fourcc='mp4v', half=False, img_size=416, iou_thres=0.5, names='C:\\\\Users\\\\lerryw\\\\Google Drive\\\\satellite_dataset\\\\worldview\\\\op.names', output='./output', save_txt=False, source='C:\\\\Development\\\\dev_tools\\\\tree-detector-yolo\\\\data\\\\digitalglobe_oilpalm_1_4.tif', view_img=False, weights='C:\\\\Users\\\\lerryw\\\\Google Drive\\\\satellite_dataset\\\\worldview\\\\weights\\\\last_oilpalm_wv_500.pt')\n",
      "Using CUDA device0 _CudaDeviceProperties(name='Quadro K620', total_memory=2048MB)\n",
      "\n",
      "Model Summary: 225 layers, 6.25733e+07 parameters, 6.25733e+07 gradients\n",
      "Total object detected :  2023\n",
      "Done. (36.004s)\n"
     ]
    }
   ],
   "source": [
    "!python detectv2.py --source=\"{source_op}\" \\\n",
    "--output=./output \\\n",
    "--cfg=\"{cfg_op}\" \\\n",
    "--weights=\"{weights_op}\" \\\n",
    "--names=\"{names_op}\" \\\n",
    "--conf-thres 0.2 \\\n",
    "--iou-thres 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# a = torch.tensor(())\n",
    "# for i in range(3):\n",
    "#     # if i = torch.tensor(1)\n",
    "#     # it cannot be cat, since it has \n",
    "#     # zero dimention.\n",
    "#     # Also use .float() to make sure that they \n",
    "#     # are in the same dtype\n",
    "#     i = torch.tensor([i]).float()\n",
    "#     a = torch.cat((a, i), 0)\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detectv2.py --source=data/samples/zidane.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source =\"C:\\\\Map\\\\Deep_learning\\\\digital_globe\\\\011802594010_01\\\\pansharp_rgb_tiles\\\\765\\\\tiles\"\n",
    "# cfg =\"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\satellite_dataset\\\\worldview\\\\cfg\\\\yolov3_spp_1cls_op.cfg\"\n",
    "# weights =\"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\satellite_dataset\\\\worldview\\\\weights\\\\best_oilpalm_wv_500.pt\"\n",
    "# names =\"C:\\\\Users\\\\lerryw\\\\Google Drive\\\\satellite_dataset\\\\worldview\\\\op.names\"\n",
    "# outDir=\"C:\\\\Map\\\\Deep_learning\\\\digital_globe\\\\011802594010_01\\\\pansharp_rgb_tiles\\\\765\\\\yolo\"\n",
    "# conf_thres = 0.2\n",
    "# iou_thres = 0.1 \n",
    "\n",
    "# !python detect.py \\\n",
    "# --source=\"{source}\" \\\n",
    "# --save-label \\\n",
    "# --cfg=\"{cfg}\" \\\n",
    "# --weights=\"{weights}\" \\\n",
    "# --names=\"{names}\" \\\n",
    "# --conf-thres=\"{conf_thres}\" \\\n",
    "# --iou-thres=\"{iou_thres}\" \\\n",
    "# --output=\"{outDir}\" \\\n",
    "# --augment\n",
    "\n",
    "# # showall(outfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import to_tiles\n",
    "path_wv=r\"C:\\Map\\Deep_learning\\digital_globe\\011802594010_01\\pansharp_rgb_tiles\\765\\keresa.tif\"\n",
    "outFd = r\"C:\\Map\\Deep_learning\\digital_globe\\011802594010_01\\pansharp_rgb_tiles\\765\\using_slice\"\n",
    "to_tiles(path_wv,outFd,416,416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice image\n",
    "from utils.slice import slice_im\n",
    "input_img=r'C:\\Map\\Deep_learning\\digital_globe\\011802594010_01\\pansharp_rgb_tiles\\765\\keresa.tif'\n",
    "out_name='img_sliced'\n",
    "out_dir=r'C:\\Map\\Deep_learning\\digital_globe\\011802594010_01\\pansharp_rgb_tiles\\765\\using_slice'\n",
    "slice_im(input_img,out_name,out_dir,sliceHeight=416, sliceWidth=416,\n",
    "         zero_frac_thresh=0.2, overlap=0, slice_sep='_',\n",
    "         out_ext='.png', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=cv2.imread(input_img, cv2.IMREAD_LOAD_GDAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(input_img) as src:\n",
    "    if src.transform is None or src.crs is None:\n",
    "        raise SystemExit(print(\"[ ERROR! ] Input image file \" + inputfile + \\\n",
    "                               \" is not a geographic raster. System exit!\"))\n",
    "    # frame = src.read()\n",
    "    image_crs = src.crs\n",
    "    affine = src.transform\n",
    "    src_meta = src.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_window = rasterio.windows.Window(0, 0, 416, 416)\n",
    "tile_affine = rasterio.windows.transform(tile_window, smaller_image_affine)\n",
    "tile_image = smaller_image[(slice(None),) + tile_window.toslices()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img = np.transpose(img, (2, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "outdir=r'C:\\Map\\Deep_learning\\digital_globe\\011802594010_01\\pansharp_rgb_tiles\\765\\test_out.tif'\n",
    "with rio.open(outdir, 'w', **src_meta) as dst:\n",
    "    dst.write(out_img, [3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import convert\n",
    "\n",
    "convert(cfg=r'C:\\\\Users\\\\lerryw\\\\Google Drive\\\\acacia_dataset\\\\cfg\\\\yolov3-spp-1cls.cfg',\n",
    "        weights=r'C:\\\\Users\\\\lerryw\\\\Google Drive\\\\acacia_dataset\\\\weights\\\\last_1cls_1300.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "from copy import copy\n",
    "from pathlib import Path\n",
    "from sys import platform\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "def plots(start=0, stop=0, bucket='', id=()):  # from utils.utils import *; plot_results()\n",
    "    # Plot training 'results*.txt' as seen in https://github.com/ultralytics/yolov3#training\n",
    "    fig, ax = plt.subplots(2, 4, figsize=(12, 6), tight_layout=True)\n",
    "    ax = ax.ravel()\n",
    "    # s = ['GIoU', 'Objectness', 'Classification', 'Precision', 'Recall',\n",
    "    #      'val GIoU', 'val Objectness', 'val Classification', 'mAP@0.5', 'F1']\n",
    "    s = ['GIoU', 'Objectness', 'Precision', 'Recall',\n",
    "         'val GIoU', 'val Objectness', 'mAP@0.5', 'F1']\n",
    "    if bucket:\n",
    "        os.system('rm -rf storage.googleapis.com')\n",
    "        files = ['https://storage.googleapis.com/%s/results%g.txt' % (bucket, x) for x in id]\n",
    "    else:\n",
    "        files = glob.glob(r'C:\\Users\\lerryw\\Google Drive\\satellite_dataset\\worldview\\results\\*_wv_*.txt') #+ glob.glob('../../Downloads/results*.txt')\n",
    "\n",
    "    for f in sorted(files,reverse=True):\n",
    "        try:\n",
    "            # results = np.loadtxt(f, usecols=[2, 3, 4, 8, 9, 12, 13, 14, 10, 11], ndmin=2).T\n",
    "            results = np.loadtxt(f, usecols=[2, 3, 8, 9, 12, 13, 10, 11], ndmin=2).T\n",
    "            n = results.shape[1]  # number of rows\n",
    "            x = range(start, min(stop, n) if stop else n)\n",
    "            for i in range(8):\n",
    "                y = results[i, x]\n",
    "                if i in [0, 1, 2, 5, 6, 7]:\n",
    "                    y[y == 0] = np.nan  # dont show zero loss values\n",
    "                    # y /= y[0]  # normalize\n",
    "                ax[i].plot(x, y, marker='', label=Path(f).stem, linewidth=2, markersize=8)\n",
    "                ax[i].set_title(s[i])\n",
    "                # if i in [5, 6, 7]:  # share train and val loss y axes\n",
    "                #     ax[i].get_shared_y_axes().join(ax[i], ax[i - 5])\n",
    "        except:\n",
    "            print('Warning: Plotting error for %s, skipping file' % f)\n",
    "\n",
    "    ax[1].legend()\n",
    "    fig.savefig(r'C:\\Users\\lerryw\\Google Drive\\satellite_dataset\\worldview\\results\\results.png', dpi=360)\n",
    "\n",
    "plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "from copy import copy\n",
    "from pathlib import Path\n",
    "from sys import platform\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "def plots(start=0, stop=0, bucket='', id=()):  # from utils.utils import *; plot_results()\n",
    "    # Plot training 'results*.txt' as seen in https://github.com/ultralytics/yolov3#training\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12, 6), tight_layout=True)\n",
    "    ax = ax.ravel()\n",
    "    s = ['Precision', 'Recall', 'mAP@0.5', 'F1']\n",
    "    files = glob.glob(r'C:\\Users\\lerryw\\Google Drive\\satellite_dataset\\worldview\\results\\results_oilpalm_wv_500.txt') #+ glob.glob('../../Downloads/results*.txt')\n",
    "    for f in sorted(files):\n",
    "        try:\n",
    "            results = np.loadtxt(f, usecols=[8, 9, 10, 11], ndmin=2).T\n",
    "            n = results.shape[1]  # number of rows\n",
    "            x = range(start, min(stop, n) if stop else n)\n",
    "            for i in range(4):\n",
    "                y = results[i, x]\n",
    "                if i in [0, 1, 2, 5, 6, 7]:\n",
    "                    y[y == 0] = np.nan  # dont show zero loss values\n",
    "                    # y /= y[0]  # normalize\n",
    "                ax[i].plot(x, y, marker='', label=Path(f).stem, linewidth=2, markersize=8)\n",
    "                ax[i].set_title(s[i])\n",
    "                # if i in [5, 6, 7]:  # share train and val loss y axes\n",
    "                #     ax[i].get_shared_y_axes().join(ax[i], ax[i - 5])\n",
    "        except:\n",
    "            print('Warning: Plotting error for %s, skipping file' % f)\n",
    "\n",
    "    ax[1].legend()\n",
    "    fig.savefig(r'C:\\Users\\lerryw\\Google Drive\\satellite_dataset\\worldview\\results\\results_oilpalm_wv_500.png', dpi=360)\n",
    "\n",
    "plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "from copy import copy\n",
    "from pathlib import Path\n",
    "from sys import platform\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "def plots(start=0, stop=0, bucket='', id=()):  # from utils.utils import *; plot_results()\n",
    "    # Plot training 'results*.txt' as seen in https://github.com/ultralytics/yolov3#training\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(12, 6), tight_layout=True)\n",
    "    ax = ax.ravel()\n",
    "    # s = ['GIoU', 'Objectness', 'Classification', 'Precision', 'Recall',\n",
    "    #      'val GIoU', 'val Objectness', 'val Classification', 'mAP@0.5', 'F1']\n",
    "    s = ['GIoU', 'val GIoU']\n",
    "    if bucket:\n",
    "        os.system('rm -rf storage.googleapis.com')\n",
    "        files = ['https://storage.googleapis.com/%s/results%g.txt' % (bucket, x) for x in id]\n",
    "    else:\n",
    "        files = glob.glob(r'C:\\Users\\lerryw\\Google Drive\\satellite_dataset\\worldview\\results\\results_oilpalm_wv_500.txt') #+ glob.glob('../../Downloads/results*.txt')\n",
    "    for f in sorted(files):\n",
    "        try:\n",
    "            # results = np.loadtxt(f, usecols=[2, 3, 4, 8, 9, 12, 13, 14, 10, 11], ndmin=2).T\n",
    "            results = np.loadtxt(f, usecols=[2, 12], ndmin=2).T\n",
    "            n = results.shape[1]  # number of rows\n",
    "            x = range(start, min(stop, n) if stop else n)\n",
    "            for i in range(2):\n",
    "                y = results[i, x]\n",
    "                if i in [0, 1, 2, 5, 6, 7]:\n",
    "                    y[y == 0] = np.nan  # dont show zero loss values\n",
    "                    # y /= y[0]  # normalize\n",
    "                ax[i].plot(x, y, marker='', label=Path(f).stem, linewidth=2, markersize=8)\n",
    "                ax[i].set_title(s[i])\n",
    "                # if i in [5, 6, 7]:  # share train and val loss y axes\n",
    "                #     ax[i].get_shared_y_axes().join(ax[i], ax[i - 5])\n",
    "        except:\n",
    "            print('Warning: Plotting error for %s, skipping file' % f)\n",
    "\n",
    "    ax[1].legend()\n",
    "#     fig.savefig(r'C:\\Users\\lerryw\\Google Drive\\satellite_dataset\\worldview\\results\\results.png', dpi=360)\n",
    "\n",
    "plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
